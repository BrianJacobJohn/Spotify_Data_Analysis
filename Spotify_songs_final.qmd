---
title: "STP 311 Final_Project"
format: docx
editor: visual
---

### Spotify_data

```{r}
#| output: false
#| echo: false
library(dplyr)
library(mosaic)
library(ggplot2)
library(lars)
library(olsrr)
```

Of all the art forms in existence, music is one that has seen widespread influence and success like few others. Even though TV shows and movies have a 'visual' advantage over music, the latter still thrives in the modern age, raking in 31.2 billion USD for FY2022. This success is not just a fluke though. There definitely is something to be said about the ability of music to transcend the failings of spoken language through means of varied instrumentation and above all, the sheer genius of certain artists to manipulate voices and instruments to make songs transcendent of their time. For example, the song Bohemian Rhapsody by British band Queen stops me in my tracks just as much today as it did 5 years ago when I first discovered it. A lot of memories (be they happy or sad) are likely associated with certain songs as well, making music an integral part of the lives of many people. 

The seeming nobility of music is swiftly brought down by the nature of the 'industry' that generates it. Yes, I use the word 'generates' quite consciously, and this is most certainly the result of musical endeavors being treated more as commercial opportunities rather than a means of expression. Instead of moving into the clear negatives created as a result of the  , it would be more fitting to talk about one of the benefits of commercializing music: accessibility. This brings us to music-streaming services, the modern embodiment of accessibility. These services offer at a nominal price, the access to digital libraries of a vast ocean of music from different genres. The biggest player in this space is Spotify, a company started in 2006 by Swedish entrepreneurs Daniel Ek and Martin Lorentzon. [As of 2023](https://www.driveresearch.com/market-research-company-blog/music-streaming-statistics/#:~:text=Spotify%20holds%20the%20position%20as,million%20monthly%20active%20users%20worldwide.), the service has over 210 million paid subscribers and 510 million monthly active users worldwide. Our data was taken from Tidy Tuesday's compilation of Spotify's internal metrics on different aspects of songs such as danceability, key, mode, duration of time, instrumentalness, liveness, and valence, amongst other things. The intention is to use this data to answer the question:

**What qualities of a song are the most important contributers to its danceability score?**\

Before proceeding, here is a small list of the aforementioned song traits, courtesy of Tidy Tuesday's readme page:

![](images/Screenshot%202023-11-29%20at%203.17.19%20PM-02.png){fig-align="center" width="586"}

If interested, the explanations for other such traits can be found [here](https://github.com/rfordatascience/tidytuesday/blob/master/data/2020/2020-01-21/readme.md). 

All in all, there were 32833 observations and 23 columns (16 of which are numeric) in the dataset as imported from Tidy Tuesday. There was no cleaning that needed to be performed, as the data was structured perfectly by default and it is mentioned here that we will randomly sample 10000 observations to use for our tests.

```{r}
#| echo: false
#| output: false
dat_music <- read.csv("https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2020/2020-01-21/spotify_songs.csv")
dat_music_classes <- tibble(colnames(dat_music))
dat_music_classes$classes <- sapply(dat_music,class)
```

Here are some summary statistics of danceability:

```{r}
#| echo: false
cat("Favstats mosaic \n")
cat("----------------")
t(round(x = favstats(dat_music$danceability),digits = 4))
cat("----------------")
```

Here is a histogram and frequency polygon of the danceability trait for ease of visualization. We notice a left skew present in the plot and it is unimodal as well.

```{r}
#| echo: false
hist(x = dat_music$danceability,col = "darkgreen",main = "Danceability Histogram",xlab = "Danceability")
freqpoly(x = dat_music$danceability,col = "red3",main = "Danceability Frequency Polygon",xlab = "Danceability")
```

## [Methodology & Results]{.underline}:

Initially, we will fit an [additive multiple linear regression model]{.underline} and proceed from there. First, we initialize our sampled data and remove the non-numeric parameters. While most of the columns are classified correctly, we correct for "mode" and "key" as factors. This is because "mode" is a 0 or 1 entry and "key" represents the 11 keys in music.

```{r}
#| echo: false
set.seed(512)
music_sampled <- sample_n(tbl = dat_music,size = 10000,replace = FALSE)
music_reduced <- music_sampled[,sapply(music_sampled, is.numeric)]
music_reduced$mode <- factor(music_reduced$mode)
music_reduced$key <- factor(music_reduced$key)
```

### [Naive Linear Model]{.underline}:

Here is our model and ANOVA table:

```{r}
#| echo: false
#| warning: false
music_lm_naive <- lm(danceability~.,data = music_reduced)
summary(music_lm_naive)
cat("---------------------\n")
anova(music_lm_naive)
```

Technically, we get the answer to our question here by noticing from the ANOVA that all the predictors are highly significant. The model iteslf is also significant. However, in regards to model utility, the $R^2_{adj}$ doesn't seem convincing as it implies that our model is only able to explain 24.8% of the data.

Here are the residual plots to help with checking model assumptions:

1.  [**Independence**]{.underline}: This assumption is clearly violated as there are multiple songs by the same individual in the dataset. Even though we have randomly sampled our set, there is a non-zero probability of this happening. So, our data is not independent.
2.  [**Linearity**]{.underline}: From the residual plot below, we don't see any non-linear pattern that would raise any flags. So, we consider this assumption to hold.

```{r}
#| echo: false
rg <- range(music_lm_naive$fitted.values)
ggplot(music_lm_naive)+geom_point(aes(music_lm_naive$fitted.values,y = music_lm_naive$residuals),colour = "black")+geom_abline(slope = 0,intercept = 0,colour = "green",linetype = "dashed")+ggtitle(label = "Residual plot")+theme_bw()+theme(plot.title = element_text(hjust = 0.5),axis.title.x.bottom = element_text(hjust = 0.5),axis.title.y.left = element_text(vjust = 0.5))+labs(x = "Fitted values", y = "Residuals")
```

3.  [**Homoscedasticity**]{.underline}: Again, using the same residual plot, we notice the lack of a funnel-like shape here. So, this assumption is not violated.

```{r}
#| echo: false
standardized_res <- rstandard(model = music_lm_naive)

ggplot(data = music_lm_naive,aes(x = music_lm_naive$fitted.values,y = standardized_res))+geom_point(inherit.aes = TRUE)+labs(title = "Scale-Location Plot",x = "Fitted Values",y = "Sqrt(Standardized Residuals)")+theme_bw()+theme(plot.title = element_text(hjust = 0.5))
```

4.  [**Normality**]{.underline}: As we have more than 5000 observations, solely relying on a quantitative test of normality would not be the best way to go here. This is because normality tests can be overly sensitive at large sample sizes. So, we will rely on a qualitative way to check this assumption. Using the plot below, we see that there is noticeable deviation at the tails. While one can go either way on this, we will consider this a violation of the assumption.

```{r}
#| echo: false
ggplot(data = music_lm_naive,mapping = aes(sample = music_lm_naive$residuals))+stat_qq(distribution = stats::qnorm,inherit.aes = TRUE)+stat_qq_line(inherit.aes = TRUE,colour = "darkgreen")+labs(title = "Q-Q plot",x = "Theoretical Quantiles",y = "Standard Residuals")+theme_bw()+theme(plot.title = element_text(hjust = 0.5))
```

5.  [**Cook's distance (Influential points and outliers)**]{.underline}: Clearly, there are issues with influential points in our model. I have marked the top five most influential points with brown dots, but even if you ignored these points, there are multiple other points that lie beyond the green threshold.

```{r}
#| warning: false
#| echo: false
a <- fortify(model = music_lm_naive)

list_1 <- order(a$.cooksd,decreasing = TRUE)[1:5]
list_1_cook <- a$.cooksd[list_1]
end_list<-data.frame(list_1,list_1_cook)

ggplot(data = a, mapping = aes(c(1:dim(a)[1]),a$.cooksd))+geom_line(inherit.aes = TRUE)+theme_bw()+geom_point(mapping = aes(x = end_list$list_1,y = end_list$list_1_cook),colour = "saddlebrown",data = end_list)+labs(x = "Observation number",y = "Cook's Distance",title = "Cook's Distance")+geom_abline(slope = 0,intercept = 4/(dim(dat_music)[1]-length(music_lm_naive$rank)-1),colour = "springgreen",linetype = "dashed")+theme(plot.title = element_text(hjust = 0.5))
```

Here is the largest influential points from our sampled data. Interestingly, it is a four second song by Japanese band DREAMS COME TRUE, who have [1.5 Million followers](https://open.spotify.com/artist/2mJOGcLR3aCHkM1uAF93or) as of 11/29/2023.

```{r}
#| echo: false
cat(paste(music_sampled[which.max(a$.cooksd),], collapse = "\n"))
```

Overall, the point of fitting the linear model was in order to 'test the waters.' To improve upon this, we will use a lasso selection process, which will appropriately inflate/deflate the $\beta$'s depending upon their relative importance/unimportnace.

```{r}
#| echo: false
music_matrix <- model.matrix(music_lm_naive)
music_lasso_lm <- lars(x = music_matrix,y = music_reduced$danceability,type = "lasso",intercept = TRUE)
print(music_lasso_lm)
cat("\nLASSO Coefficients\n")
cat("------------------\n")
coef(music_lasso_lm)[23,]
cat("------------------\n")
plot(music_lasso_lm)
```

Here, we see that our $R^2_{adj}$ has unfortunately only improved slightly (0.25) compared to the previous model (0.248). Could there be an issue of multicollinearity? To test this, we plot the GVIF's (Generalized Variance Inflation Factor) for each predictor.

```{r}
#| echo: false
#| message: false
c <- car::vif(mod = music_lm_naive)
b <- fortify(data.frame(c[,1]))
b[,2] <- c(1:dim(b)[1])
ggplot(data = b,mappin = aes(x = V2,y = c...1.))+geom_point(inherit.aes = TRUE,color = "darkgreen")+theme_bw()+labs(x = "Index (1 to 12)",y = "GVIF",title ="GVIF plot")+theme(plot.title = element_text(hjust = 0.5))
```

The largest GVIF is approximately 2.5, which implies moderate correlation to other predictors. For most predictors the GVIF is marginally above 1, implying little to no correlation with other predictors. Thus, with a little hand-waving, we can scratch out multicollinearity as being a problem here.

## [**Discussion & Conclusion**]{.underline}

So, where does that leave us? Well, not far from where we started! LASSO did not lead us to a better place (in terms of $R^2_{adj}$ at least) as we had hoped. With that said, issues such as those of normality and influential points are not straightforward to solve and are to be handled with a lot of care. Finally, our decision to use the predictors that ended up in our naive model was a choice that was well-deliberated. The assumption was that different aspects of a song (be they instrumental or otherwise) ultimately contribute to its danceability metric. However, we are aware of the possibility that this may not be the best move. Perhaps people consider shorter songs to be more danceable. Or something else like so. The mentality of a culture is much more difficult to predict, and a more in-depth analysis would be required to understand this complex effect.

Assuming one wants to still work with our model as it is now, there are three remedies that would be use: Response transformations, considering interaction terms, and trying a non-parametric model. We will briefly present our reasoning for the viability of the three processes.

1.  [**Response transformations**]{.underline}: One would go about this by first conducting a boxcox procedure, which would suggest an appropriate transformation on the response and then create a new linear model using the transformed response. What's the problem here? Well, boxcox needs strictly positive values in the response. Even zeroes are not allowed. Unfortunately there are many songs here that have zeroes for their danceability score. Thus, unless you're okay with deleting a chunk of songs, this approach is not recommended at all.

    Here's a sample of what happense if you use R to do the boxcox procedure.

    ```{r}
    #| error: TRUE
    MASS:: boxcox(object = music_lm_naive)
    ```

2.  [**Considering Interaction terms**]{.underline}: This approach is a double edged sword in our opinion. On one hand, the $R^2_{adj}$ shoots up proportional to the order of interactions in the model. For example, we ran the linear model with first order interactions and the new model was able to explain 31% of the total variation, which is about a 10% increase from before. Here's that in R:

    ```{r}
    # Neat little trick to generate first order interactions without writing everything out in R
    music_lm_interact <- lm(danceability~.^2,data = music_reduced)
    summ <- summary(object = music_lm_interact)
    # Adjusted R squared
    summ$adj.r.squared
    ```

Running the LASSO on this model, the $R^2_{adj}$ increases to about 35%. All seems great so far.\
However, one big problem is in regards to overfitting the model with useless predictors. Take a look at the last ten predictors and compare it to our naive model from before:

```{r}
tail(anova(music_lm_interact),10)
```

Thus, one should use this to make selective interactions that would strengthen the overall model.

3.  [**Non-parametric model**]{.underline}: This is much more random suggestion as compared to previous two. However, using the logic mentioned in (1), one should be able to see why a non-parametric approach may be beneficial.

This brings us to the end of our discussion on future improvements with regard to the Spotify model.
